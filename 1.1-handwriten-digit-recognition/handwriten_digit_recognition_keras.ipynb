{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import TensorBoard,EarlyStopping\n",
    "\n",
    "\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparation():\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.x_train = None\n",
    "        self.y_train = None\n",
    "        self.x_test = None\n",
    "        self.y_test = None\n",
    "        self.num_classes = None\n",
    "        \n",
    "        \n",
    "    def load_data(self):\n",
    "        (self.x_train, self.y_train), (self.x_test, self.y_test) = tf.keras.datasets.mnist.load_data(path=os.path.join(current_dir,'data','mnist.npz'))\n",
    "\n",
    "    '''\n",
    "    In Keras, the layers used for two-dimensional convolutions expect pixel values with the dimensions \n",
    "    [pixels][width][height][channels].\n",
    "    We’ll use the .reshape() method to perform this action. \n",
    "    Finally, normalize the image data by dividing each pixel value by 255.\n",
    "    (since RGB value can range from 0 to 255)\n",
    "    reshape to be [samples][width][height][channels]\n",
    "    \n",
    "    we need to convert the dependent variable in the form of integers to a binary class matrix. \n",
    "    This can be achieved by the to_categorical() function\n",
    "\n",
    "    '''    \n",
    "    def reshape_data(self):\n",
    "        img_rows, img_cols = 28, 28\n",
    "        print(\"Before: \")\n",
    "        print(self.x_train.shape)\n",
    "        print(self.x_test.shape)\n",
    "        self.x_train = self.x_train.reshape(self.x_train.shape[0],img_rows,img_cols,1).astype('float32')\n",
    "        self.x_test = self.x_test.reshape(self.x_test.shape[0],img_rows,img_cols,1).astype('float32')\n",
    "        self.x_train /= 255\n",
    "        self.x_test /= 255\n",
    "        print(\"After: \")\n",
    "        print(self.x_train.shape)\n",
    "        print(self.x_test.shape)\n",
    "        self.y_train = to_categorical(self.y_train)\n",
    "        self.y_test = to_categorical(self.y_test)\n",
    "        self.num_classes = self.y_test.shape[1]\n",
    "        print(self.num_classes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_obj = DataPreparation()     \n",
    "dp_obj.load_data()\n",
    "dp_obj.reshape_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first hidden layer is a convolutional layer called a Convolution2D. The layer has 32 feature maps, which with the size of 5×5 and a rectifier activation function. This is the input layer, expecting images with the structure outline above [pixels][width][height].\n",
    "2. Next we define a pooling layer that takes the max called MaxPooling2D. It is configured with a pool size of 2×2.\n",
    "3. The next layer is a regularization layer using dropout called Dropout. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n",
    "4. Next is a layer that converts the 2D matrix data to a vector called Flatten. It allows the output to be processed by standard fully connected layers.\n",
    "5. Next a fully connected layer with 128 neurons and rectifier activation function.\n",
    "6. Finally, the output layer has 10 neurons for the 10 classes and a softmax activation function to output probability-like predictions for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelDesign():\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.num_classes = dp_obj.num_classes\n",
    "        self.history = None\n",
    "        self.keras_callbacks_list = []\n",
    "        '''\n",
    "        if apply_tensorboard_callbacks:\n",
    "            tensorboard = TensorBoard(log_dir='./logs',histogram_freq=1,write_images=True)\n",
    "            self.keras_callbacks = [tensorboard]\n",
    "        '''\n",
    "    def set_call_back(self,apply_callback,tensorboard_callback):\n",
    "        if apply_callback:\n",
    "            es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=60)\n",
    "            self.keras_callbacks_list.append(es)\n",
    "        if tensorboard_callback:\n",
    "            tensorboard = TensorBoard(log_dir='./logs',histogram_freq=1,write_images=True)\n",
    "            self.keras_callbacks_list.append(tensorboard)\n",
    "        \n",
    "    def base_model(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(32,(5,5),activation='relu'))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        self.model.add(Dropout(0.2))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(self.num_classes,activation=\"softmax\"))\n",
    "        \n",
    "    def compile_model(self):\n",
    "        self.model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "    \n",
    "    def train_model(self,batch_size,epochs):\n",
    "        x_train = dp_obj.x_train\n",
    "        y_train = dp_obj.y_train\n",
    "        x_test = dp_obj.x_test\n",
    "        y_test = dp_obj.y_test        \n",
    "        self.history = self.model.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, \n",
    "                                      verbose=2, validation_data = (x_test,y_test),shuffle=True,\n",
    "                                     callbacks=self.keras_callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "md_obj = ModelDesign()\n",
    "\"You can skip the line or set the flag according to your needs\"\n",
    "md_obj.set_call_back(True,True)\n",
    "md_obj.base_model()\n",
    "md_obj.compile_model()\n",
    "md_obj.train_model(batch_size,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = md_obj.model.evaluate(dp_obj.x_test, dp_obj.y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateModel():\n",
    "    def __init__(self,history):\n",
    "        self.history = history\n",
    "        self.epochs = range(len(epochs))\n",
    "        \n",
    "    def plot_acc_loss(self):\n",
    "        \n",
    "        acc = history.history['acc']\n",
    "        loss = history.history['loss']\n",
    "\n",
    "        plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "        plt.title('Training accuracy')\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "        plt.title('Training loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "em_obj = EvaluateModel(md_obj.history)\n",
    "em_obj.plot_acc_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import Image as IMG\n",
    "\n",
    "\n",
    "class Prediction():\n",
    "    \n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    \n",
    "    def predict(self,image):\n",
    "        img = Image.open(image)\n",
    "        print(\"Image: \")\n",
    "        display(IMG(filename=image))\n",
    "        img = img.convert(\"L\")\n",
    "        img = img.resize((28,28))\n",
    "        im2arr = np.array(img)\n",
    "        im2arr = im2arr.reshape(1,28,28,1)\n",
    "        y_pred = self.model.predict(im2arr)\n",
    "        return y_pred\n",
    "        \n",
    "pred_obj = Prediction(md_obj.model)\n",
    "files = None\n",
    "\n",
    "for r,d,f in os.walk(os.path.join(current_dir,\"Test_Data\")):\n",
    "    files = f\n",
    "for item in files:\n",
    "    result = pred_obj.predict(os.path.join(current_dir,\"Test_Data\",item))\n",
    "    print(\"Predition Label: \",result.argmax(),'\\n')\n",
    "    #print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
