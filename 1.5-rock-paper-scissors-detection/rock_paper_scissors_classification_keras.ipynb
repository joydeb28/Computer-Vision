{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loading():\n",
    "    def __init__(self):\n",
    "        local_zip = 'rps.zip'\n",
    "        zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "        zip_ref.extractall('train_data/')\n",
    "        zip_ref.close()\n",
    "        \n",
    "        local_zip = 'rps-validation.zip'\n",
    "        zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "        zip_ref.extractall('test_data/')\n",
    "        zip_ref.close()\n",
    "        \n",
    "        local_zip = 'rps-test-set.zip'\n",
    "        zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "        zip_ref.extractall('test_data/')\n",
    "        zip_ref.close()\n",
    "        \n",
    "        self.rock_dir = os.path.join('train_data/rock')\n",
    "        self.paper_dir = os.path.join('train_data/paper')\n",
    "        self.scissors_dir = os.path.join('train_data/scissors')\n",
    "        \n",
    "        print('total training rock images:', len(os.listdir(rock_dir)))\n",
    "        print('total training paper images:', len(os.listdir(paper_dir)))\n",
    "        print('total training scissors images:', len(os.listdir(scissors_dir)))\n",
    "        \n",
    "        self.rock_files = os.listdir(rock_dir)\n",
    "        print(rock_files[:10])\n",
    "        \n",
    "        self.paper_files = os.listdir(paper_dir)\n",
    "        print(paper_files[:10])\n",
    "        \n",
    "        self.scissors_files = os.listdir(scissors_dir)\n",
    "        print(scissors_files[:10])\n",
    "        \n",
    "        \n",
    "        self.next_rock = None\n",
    "        self.next_paper = None\n",
    "        self.next_scissors = None\n",
    "        \n",
    "    def show_images(self):\n",
    "        pic_index = 2\n",
    "        \n",
    "        self.next_rock = [os.path.join(self.rock_dir, fname) \n",
    "                        for fname in self.rock_files[pic_index-2:pic_index]]\n",
    "        self.next_paper = [os.path.join(self.paper_dir, fname) \n",
    "                        for fname in self.paper_files[pic_index-2:pic_index]]\n",
    "        self.next_scissors = [os.path.join(self.scissors_dir, fname) \n",
    "                        for fname in self.scissors_files[pic_index-2:pic_index]]\n",
    "        \n",
    "        for i, img_path in enumerate(self.next_rock+self.next_paper+self.next_scissors):\n",
    "          #print(img_path)\n",
    "          img = mpimg.imread(img_path)\n",
    "          plt.imshow(img)\n",
    "          plt.axis('Off')\n",
    "          plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rock_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e319db82d80c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_data_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoading\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-a1d4f545e732>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscissors_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_data/scissors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total training rock images:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrock_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total training paper images:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaper_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total training scissors images:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscissors_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rock_dir' is not defined"
     ]
    }
   ],
   "source": [
    "load_data_obj = Loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rock_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1e83078e33c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_data_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-bd53b3c83c24>\u001b[0m in \u001b[0;36mshow_images\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         self.next_rock = [os.path.join(rock_dir, fname) \n\u001b[0;32m---> 39\u001b[0;31m                         for fname in rock_files[pic_index-2:pic_index]]\n\u001b[0m\u001b[1;32m     40\u001b[0m         self.next_paper = [os.path.join(paper_dir, fname) \n\u001b[1;32m     41\u001b[0m                         for fname in paper_files[pic_index-2:pic_index]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rock_files' is not defined"
     ]
    }
   ],
   "source": [
    "load_data_obj.show_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessig(object):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.train_generator = None\n",
    "        self.train_generator = None     \n",
    "        \n",
    "    def image_augmentation(self):\n",
    "        \n",
    "        TRAINING_DIR = \"/daa/rps/\"\n",
    "        training_datagen = ImageDataGenerator(\n",
    "            rescale = 1./255,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')\n",
    "        \n",
    "        self.train_generator = training_datagen.flow_from_directory(\n",
    "            TRAINING_DIR,\n",
    "            target_size=(150,150),\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        VALIDATION_DIR = \"/data/rps-test-set/\"\n",
    "        validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "        self.validation_generator = validation_datagen.flow_from_directory(\n",
    "            VALIDATION_DIR,\n",
    "            target_size=(150,150),\n",
    "            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_obj = Preprocessing()\n",
    "preprocess_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DesignModel():\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.acc = None\n",
    "        self.val_acc = None\n",
    "        self.loss = None\n",
    "        self.val_loss = None \n",
    "        \n",
    "    def create_model(self):\n",
    "\n",
    "        self.model = tf.keras.models.Sequential()\n",
    "        \n",
    "            tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            # The second convolution\n",
    "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            # The third convolution\n",
    "            tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            # The fourth convolution\n",
    "            tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            # Flatten the results to feed into a DNN\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            # 512 neuron hidden layer\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        self.model.summary()\n",
    "        \n",
    "        self.model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "        \n",
    "        self.history = self.model.fit_generator(self.train_generator, epochs=25, validation_data = self.validation_generator, verbose = 1)\n",
    "\n",
    "        self.model.save(\"rps.h5\")\n",
    "\n",
    "    def get_mattrics(self):\n",
    "        \n",
    "        self.acc = self.history.self.history['acc']\n",
    "        self.val_acc = self.history.self.history['val_acc']\n",
    "        self.loss = self.history.self.history['loss']\n",
    "        self.val_loss = self.history.self.history['val_loss']\n",
    "\n",
    "    def plot_accuracy(self):\n",
    "        epochs = range(len(self.acc))\n",
    "        \n",
    "        plt.plot(epochs, self.acc, 'r', label='Training accuracy')\n",
    "        plt.plot(epochs, self.val_acc, 'b', label='Validation accuracy')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.legend(loc=0)\n",
    "        plt.figure()\n",
    "        \n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    def predict(self,path):\n",
    "      img = image.load_img(path, target_size=(150, 150))\n",
    "      x = image.img_to_array(img)\n",
    "      x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "      images = np.vstack([x])\n",
    "      classes = self.model.predict(images, batch_size=10)\n",
    "      print(img)\n",
    "      print(classes)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rock images: 840\n",
      "total training paper images: 840\n",
      "total training scissors images: 840\n",
      "['rock01-108.png', 'rock03-112.png', 'rock06ck02-084.png', 'rock02-002.png', 'rock03-086.png', 'rock03-102.png', 'rock07-k03-009.png', 'rock04-071.png', 'rock04-036.png', 'rock06ck02-049.png']\n",
      "['paper04-087.png', 'paper03-025.png', 'paper07-036.png', 'paper01-024.png', 'paper04-034.png', 'paper04-080.png', 'paper01-011.png', 'paper05-118.png', 'paper05-038.png', 'paper04-026.png']\n",
      "['scissors01-086.png', 'scissors04-062.png', 'scissors03-065.png', 'testscissors01-095.png', 'scissors01-110.png', 'testscissors02-044.png', 'scissors03-060.png', 'testscissors02-039.png', 'testscissors01-115.png', 'scissors03-087.png']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/rps/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ca3da9d7a519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrpsd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRockPaperScissorDetection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrpsd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrpsd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrpsd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b3a8cfb81ffb>\u001b[0m in \u001b[0;36mimage_augmentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mTRAINING_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         )\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         )\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/rps/'"
     ]
    }
   ],
   "source": [
    "rpsd = RockPaperScissorDetection()\n",
    "rpsd.preprocessing()\n",
    "rpsd.image_augmentation()\n",
    "rpsd.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
